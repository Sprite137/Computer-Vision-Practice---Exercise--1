{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义显示图片的函数cv_show\n",
    "def cv_show(name, image):\n",
    "    cv2.namedWindow(name, cv2.WINDOW_NORMAL)\n",
    "    cv2.resizeWindow(name,image.shape[0],image.shape[1])\n",
    "    cv2.imshow(name, image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义SIFT检测算法函数\n",
    "def detectAndDescribe(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    descriptor=cv2.SIFT_create()\n",
    "    (kps, features) = descriptor.detectAndCompute(gray, None)       #运用SIFT检测关键点\n",
    "    kps = np.float32([kp.pt for kp in kps])\n",
    "    return (kps, features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义特征点匹配函数\n",
    "def matchKeypoints(kpsA, kpsB, featuresA, featuresB, ratio = 0.75, reprojThresh = 4.0):\n",
    "    matcher = cv2.BFMatcher()\n",
    "    rawMatches = matcher.knnMatch(featuresA, featuresB, 2)      #运用KNN算法匹配\n",
    "    matches = []\n",
    "    for m in rawMatches:\n",
    "        if len(m) == 2 and m[0].distance < m[1].distance * ratio:\n",
    "            matches.append((m[0].trainIdx, m[0].queryIdx))\n",
    "    if len(matches) > 10:       #匹配关键点的对数必须大于10，才能进行拼接\n",
    "        ptsA = np.float32([kpsA[i] for (_, i) in matches])\n",
    "        ptsB = np.float32([kpsB[i] for (i, _) in matches])\n",
    "        (H, status) = cv2.findHomography(ptsA, ptsB, cv2.RANSAC, reprojThresh)      #记录透视矩阵，方便下一步进行透视变换\n",
    "        return (matches, H, status)\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义显示匹配点连线函数\n",
    "def drawMatches(imageA, imageB, kpsA, kpsB, matches, status):\n",
    "    (hA, wA) = imageA.shape[:2]\n",
    "    (hB, wB) = imageB.shape[:2]\n",
    "    vis = np.zeros((max(hA, hB), wA + wB, 3), dtype=\"uint8\")\n",
    "    vis[0:hA, 0:wA] = imageA\n",
    "    vis[0:hB, wA:] = imageB\n",
    "    for ((trainIdx, queryIdx), s) in zip(matches, status):\n",
    "        if s == 1:\n",
    "            ptA = (int(kpsA[queryIdx][0]), int(kpsA[queryIdx][1]))\n",
    "            ptB = (int(kpsB[trainIdx][0]) + wA, int(kpsB[trainIdx][1]))\n",
    "            cv2.line(vis, ptA, ptB, (0, 255, 0), 1)     #对匹配的关键点进行连线\n",
    "    cv_show(\"drawImg\", vis)\n",
    "    return vis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义拼接函数\n",
    "def stitch(imageA,imageB, ratio=0.75, reprojThresh=4.0,showMatches=False):\n",
    "    (kpsA, featuresA) = detectAndDescribe(imageA)\n",
    "    (kpsB, featuresB) = detectAndDescribe(imageB)\n",
    "    M = matchKeypoints(kpsA, kpsB, featuresA, featuresB, ratio, reprojThresh)\n",
    "    if M is None:\n",
    "        return None     \n",
    "    (matches, H, status) = M\n",
    "    result = cv2.warpPerspective(imageA, H, (imageA.shape[1] + imageB.shape[1], imageA.shape[0]))       #将右边的图进行透视变化\n",
    "    result[0:imageB.shape[0], 0:imageB.shape[1]] = imageB       #将左边的图覆盖到已透视变换的上一步result中，得到未后处理的图像\n",
    "    if showMatches:\n",
    "        vis = drawMatches(imageA, imageB, kpsA, kpsB, matches, status)\n",
    "        return (result, vis)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义裁剪函数\n",
    "def change_size(image):\n",
    "    img = cv2.medianBlur(image,5)       #进行中值滤波\n",
    "    b=cv2.threshold(img,15,255,cv2.THRESH_BINARY)          \n",
    "    binary_image=b[1]              \n",
    "    binary_image=cv2.cvtColor(binary_image,cv2.COLOR_BGR2GRAY)      \n",
    " \n",
    "    x=binary_image.shape[0]\n",
    "    y=binary_image.shape[1]\n",
    "    edges_x=[]\n",
    "    edges_y=[]\n",
    "    for i in range(x):\n",
    "        for j in range(y):\n",
    "            if binary_image[i][j]==255:     #将像素值为255(即黑色)的点添加到边缘\n",
    "             edges_x.append(i)\n",
    "             edges_y.append(j)\n",
    "\n",
    "    #寻找边缘点\n",
    "    left=min(edges_x)               \n",
    "    right=max(edges_x)              \n",
    "    width=right-left                \n",
    "    bottom=min(edges_y)             \n",
    "    top=max(edges_y)                \n",
    "    height=top-bottom               \n",
    " \n",
    "    pre1_picture=image[left:left+width,bottom:bottom+height]        #进行裁剪       \n",
    "    cv_show('result',pre1_picture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取图像\n",
    "imageA = cv2.imread('data/6/2.png')\n",
    "imageB = cv2.imread('data/6/1.png')\n",
    "#得到关键点\n",
    "(kpsA, featuresA) = detectAndDescribe(imageA)\n",
    "(kpsB, featuresB) = detectAndDescribe(imageB)\n",
    "#进行关键点的匹配并将其拼接\n",
    "(matches,H,status) = matchKeypoints(kpsA, kpsB, featuresA, featuresB)\n",
    "drawMatches(imageA, imageB, kpsA, kpsB, matches, status)\n",
    "result = stitch(imageA, imageB)\n",
    "\n",
    "#后处理(去除黑边区域)\n",
    "change_size(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
